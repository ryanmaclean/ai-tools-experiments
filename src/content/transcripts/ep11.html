        <div class="video-container">
            <a href="https://youtu.be/DkooO8M0Xn8" target="_blank">
                <img src="../images/thumbnails/ep11.png" alt="Episode 11 Thumbnail">
            </a>
        </div>

        <div class="episode-content">
            
            <p>In this episode, Jason and Ryan explore the freshly released Llama 4 model from Meta, which was just released over the weekend. They dive into its capabilities, testing it on Hugging Face, and discuss its groundbreaking 10+ million token context window. The conversation covers whether such a massive context window might eliminate the need for RAG (Retrieval Augmented Generation) and how it could simplify prompt engineering by allowing for more detailed system prompts and guardrails. They also explore two model comparison platformsâ€”OpenRouter and LM Arenaâ€”which allow users to test and compare different AI models side by side. During their exploration, they discover a lesser-known model called LunarCall that surprisingly outperforms others on a specific test. This episode provides valuable insights into the rapidly evolving landscape of AI models and practical tools for comparing their performance.</p>
            
            <h2>Jump To</h2>
            <ul class="chapter-markers">
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=0" target="_blank">ðŸ•’</a> Introduction and discussion about Llama 4's weekend release</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=60" target="_blank">ðŸ•’</a> Exploring Llama 4 on Hugging Face</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=120" target="_blank">ðŸ•’</a> Discussion about Llama 4's 10+ million token context window</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=240" target="_blank">ðŸ•’</a> Benefits of large context windows for guardrails and PRDs</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=300" target="_blank">ðŸ•’</a> Testing Llama 4 with basic questions</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=480" target="_blank">ðŸ•’</a> Testing Llama 4 with specific knowledge questions</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=900" target="_blank">ðŸ•’</a> Introduction to model comparison tools: OpenRouter</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=1260" target="_blank">ðŸ•’</a> Introduction to LM Arena for model comparison</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=1380" target="_blank">ðŸ•’</a> Comparing models on music knowledge</li>
                <li><a href="https://youtu.be/DkooO8M0Xn8?t=1440" target="_blank">ðŸ•’</a> Discovering LunarCall, a surprising new model</li>
            </ul>
            
            <h2>Resources</h2>
            <ul>
                <li><a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" target="_blank">Llama 4 on HuggingFace</a> - Try Meta's latest language model</li>
                <li><a href="https://openrouter.ai/" target="_blank">OpenRouter</a> - Platform for comparing and routing between multiple AI models</li>
                <li><a href="https://lmarena.ai/" target="_blank">LM Arena</a> - Interactive tool for blind comparison testing of language models</li>
                <li><a href="https://deepseek.ai/" target="_blank">DeepSeek</a> - AI model mentioned in the episode comparisons</li>
            </ul>
            
            <h2>Key Takeaways</h2>
            <ul class="takeaways">
                <li>Llama 4 features a massive 10+ million token context window, potentially revolutionizing how we work with large documents and complex instructions</li>
                <li>Despite large context windows, RAG (Retrieval Augmented Generation) remains valuable for cost efficiency and performance optimization</li>
                <li>Expanded context windows enable more comprehensive guardrails and detailed system prompts in production applications</li>
                <li>Even the latest AI models still struggle with certain types of knowledge, particularly specialized programming techniques and niche factual information</li>
                <li>AI hallucinations remain a concern, particularly for factual questions, as demonstrated by the incorrect musician information</li>
                <li>Tools like OpenRouter and LM Arena provide valuable ways to compare different models for specific use cases</li>
                <li>Model comparison can reveal surprising results, such as lesser-known models (like LunarCall) outperforming more established ones on certain tasks</li>
                <li>The AI model landscape is evolving extremely rapidly, with new models being released at an unprecedented pace</li>
                <li>Blind testing through platforms like LM Arena helps eliminate bias when evaluating model performance</li>
                <li>The increasing size of training corpora is gradually improving factual knowledge, but specialized domains still present challenges</li>
            </ul>
            
            <h2>Full Transcript</h2>
            <div class="transcript-navigation">
                <button class="transcript-control" onclick="document.querySelector('.transcript').scrollTop = 0">Top</button>
                <span>Scroll or use controls to navigate</span>
                <button class="transcript-control" onclick="document.querySelector('.transcript').scrollTop = document.querySelector('.transcript').scrollHeight">Bottom</button>
            </div>
            
            <div class="timestamp-note" style="background-color: #f0f7ff; padding: 10px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #0066cc;">
                <strong>ðŸ’¡ Tip:</strong> Click on the ðŸ•’ icons above or timestamps in the transcript below to jump to that point in the YouTube video.
            </div>
            
            <div class="transcript">
                <pre>
<span class="transcript-timestamp"><a href="https://youtu.be/DkooO8M0Xn8?t=0" target="_blank">ðŸ•’</a></span> <span class="transcript-speaker">Jason Hand:</span> Hey, Ryan. What's up? 

<span class="transcript-timestamp"><a href="https://youtu.be/DkooO8M0Xn8?t=3" target="_blank">ðŸ•’</a></span> <span class="transcript-speaker">Ryan MacLean:</span> Not much. It feels like it's just been a little while this time. Only like a couple days. Yeah, three days. 

<span class="transcript-timestamp"><a href="https://youtu.be/DkooO8M0Xn8?t=10" target="_blank">ðŸ•’</a></span> <span class="transcript-speaker">Jason Hand:</span> It's Monday and we just did this on Friday, but this is good. This is, we're staying on top of things. This is the important thing. 

<span class="transcript-timestamp"><a href="https://youtu.be/DkooO8M0Xn8?t=15" target="_blank">ðŸ•’</a></span> <span class="transcript-speaker">Ryan MacLean:</span> Yeah, on that note, like I, I thought I was doing good watching the news during the week, but I didn't think there was going to be a model dropped over the weekend. Yeah, Saturday seems like a, an odd day for me at least to drop a big model, that kind of stuff. Here we are.

<span class="transcript-timestamp"><a href="https://youtu.be/DkooO8M0Xn8?t=30" target="_blank">ðŸ•’</a></span> <span class="transcript-speaker">Jason Hand:</span> It's been at least 24 hours, so something big has definitely happened in the news of AI. So yeah, LLama 4 is indeed is the thing that just came out that we just spoke right before we hit record. And we thought we would just talk a little bit about Llama 4 since it just came out and some of the tools that are. I have been on our list of things to look at a little bit closer. Some of 'em allow us to compare some different models and so maybe we'll do something like that. And keep it a little bit more on the briefer side for today's recording.

<span class="transcript-timestamp"><a href="https://youtu.be/DkooO8M0Xn8?t=60" target="_blank">ðŸ•’</a></span> <span class="transcript-speaker">Ryan MacLean:</span> Yeah, sure thing. So I'll share my screen first. I will admit that I know some about this model just because of, watching YouTube, that kind of stuff. But it's really new. So I, I assume that I could just, turn on a Lama and add it. And of course it's only been a couple days, so it's, it hasn't been added yet. It is however hosted on Hugging Face. And if you've not been to Hugging Face before, it's I don't wanna say a model repository 'cause it's a lot more than that. And we talked a little bit about Gradio before, which kind came out of Hugging Face. So this interface should look very similar to what I've been demoing in a couple earlier sessions.

[Full transcript continues...]
                </pre>
            </div>
        </div>
    </main>

    <!-- Episode Navigation -->
    <div class="episode-navigation">
        <div class="container">
            <h2>Episode Navigation</h2>
            <div class="episode-nav-links">
                <div class="nav-item">
                    <span class="nav-direction">Previous Episode:</span>
                    <div class="recording-card">
                        <h3>First Look at Windsurf & Model Context Protocol (MCP)</h3>
                        <div class="video-container">
                            <a href='/pages/ep10'>
                                <img src="../images/thumbnails/ep10.png" alt="Episode 10 Thumbnail">
                            </a>
                        </div>
                        <a class='btn' href='/pages/ep10'>View Notes</a>
                    </div>
                </div>
                
                <div class="nav-item">
                    <span class="nav-direction">Next Episode:</span>
                    <div class="recording-card">
                        <h3>Cursor Rules, Firebase Studio, and the Evolving IDE Landscape</h3>
                        <div class="video-container">
                            <a href='/pages/ep12'>
                                <img src="../images/thumbnails/ep12.png" alt="Episode 12 Thumbnail">
                            </a>
                        </div>
                        <a class='btn' href='/pages/ep12'>View Notes</a>
                    </div>
                </div>
            </div>
        </div>
    </div>
    

    <!-- Easter Egg Modal -->
    <div id="easter-egg-modal" class="easter-egg-modal">
        <div class="easter-egg-modal-content">
            <span class="easter-egg-close">&times;</span>
            <p>Sandy?</p>
        </div>
    </div>

    <script src="../script.js"></script>


